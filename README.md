# v-1  

这个玩意就是只有最基础的**用户功能**，其他的什么都没有，嘻嘻嘻，这样子先定下用户，然后那个后面就不要大规模添加用户之类的数据库了，避免像之前一样大规模改动

# v-1.2
这部分，我实现了那个用户个人**api-key**的增删改查功能，并给出相关的页面,像是那个聊天页面，我还要想办法完善，还没办法搞定它，所以这次我就先不把那个聊天页面给出来

# v-2
这部分，我调整了那个很多地方的代码，例如原先写的关于那个LLM_Chat功能的后端代码，就全部改了；然后，我的这部分代码没什么创新，就是原本项目的代码加上那个用户系统

我个人认为，这个小玩意可以很好的锻炼我个人写go语言的能力了...相比于python，还真的是有很多不一样

# v-3

这个，我添加了一个小型的**Note笔记本**功能，包含了基本的增删改查的功能

# v-3.2

这个，我更改了以往的几个问题：

-  全局变量滥用： GlobalUserService、GlobalChatService、GlobalLLMSession 等全局变量满天飞,使得单元测试困难（无法 mock 依赖）
-  错误处理粗糙： 很多地方直接 log.Fatal 一了百了，我后面返回错误让上层决定如何处理，而不是直接杀进程。
-  那个笔记功能的那个index.html当中忘记加上去的按钮

# v-3.3

这个，我改进了以下几个问题：

**数据库事务处理不足** 

比如删除会话时需要同时删除消息（ChatService.goL176-L194），如果中间步骤失败可能导致数据不一致，应该用事务包裹。
- User_service.go的 ResetPassword 方法：用 GORM 的事务包裹这三个操作，要么全成功，要么全回滚。
- Note_Service.go的 UpdateNote 方法：我感觉不需要先查询笔记是否存在，直接带条件更新就行。如果笔记不存在，RowsAffected 会是 0
- ChatService.go的 SaveChatMessage：核心操作用事务，非关键操作允许失败，我这样子修改的理由：消息 + 计数：强一致性，因为 message_count 是核心统计数据  //  标题更新：最终一致性，因为标题只是展示优化，失败了用户也能用  //  性能和一致性平衡：事务范围最小化，只保护关键数据

**配置硬编码**

main.go 里 localhost:6379 直接写死，虽然我用了 Config.InitConfig()，但 Redis 配置应该也走配置文件。

# v-3.35

我改进如下问题：

**缺少分页和限流**： GetChatSessions没有分页逻辑，用户消息多了会把内存撑爆这个问题，所以我对好些个地方进行了更改

# v-3.37

我改进了如下问题：

**缺少分页和限流**： GetChatMessages 没有分页逻辑，用户消息多了会把内存撑爆这个问题

# v -3.5

我改进了如下问题：

**流式传输的稳定性** : 就是原本小项目的流式传输无法保持超过60秒长时间传输的问题
解决方法：
- 添加超时和上下文控制 : SendMessageStream当中的ctx, cancel := context.WithTimeout(c.Request.Context(), 120*time.Second)
- 实现心跳机制 : ticker := time.NewTicker(5 * time.Second)
- 检测客户端断连 : 在每次 Flush 后检查
- 增加缓冲和错误恢复 : 在保存消息前，先把完整响应缓存到 Redis，失败了还能重试 / 考虑实现消息分段保存，而不是等整个流结束

```
Copy code
    流式传输阶段
        ↓
    每收到 chunk → AppendStreamResponse() → Redis (stream_response:session_id)
        ↓
    流式传输结束
        ↓
    GetStreamResponse() → 获取 Redis 中的完整响应
        ↓
    SaveWithRetry(重试3次) → 保存到 MySQL
        ↓
    成功/失败 → DeleteStreamResponse() → 清理 Redis 缓存
    
    我们确实实现了分段保存，但有个关键细节：

✅ 实现了：Redis 分段写入
每次 LLM 返回一个 chunk，立即写入 Redis
不等流式传输结束，就持续追加
这是真正的"分段保存"

❌ 没有实现：数据库分段写入
数据库保存仍然在流式传输结束后一次性执行
原因：数据库写入有事务开销，频繁写入会影响性能
但这不算是缺陷，因为 Redis 已经提供了可靠的缓冲
    
```

| 保存目标  | 保存方式            | 	原因                    |
|:------|:----------------|:-----------------------|
| Redis | 每次收到 chunk 立即追加 | Redis 写入快，支持增量操作，适合做缓冲 |
| 数据库   | 流式结束后一次性保存      | 数据库写入有事务开销，频繁写入影响性能    |

| 故障场景       | 如何处理                                | 
|:-----------|:------------------------------------|
| 客户端断开连接    | 断连检测触发，停止发送，但 AI 回复已在 Redis 缓存加     |
| 网络超时（120秒） | context 超时触发，流式传输终止，已接收数据在 Redis    |
| 数据库临时故障    | SaveWithRetry 重试 3 次，失败后保留 Redis 缓存 |
| Redis 故障   | 降级到内存变量，不阻塞主流程                      |
| 前端刷新页面     | 可调用 /chat/recover 恢复 AI 的部分回复       |

| 场景        | 修改前                       | 	修改后                    |
|:----------|:--------------------------|:------------------------|
| 正常流式传输    | AI 回复只在内存变量中，数据库保存失败就全丢了	 | AI 回复实时写入 Redis，保存失败可重试 |
| 网络中断      | AI 回复丢失，用户看不到任何内容         | AI 回复在 Redis 缓存，可恢复     |
| 数据库故障     | AI 回复全部丢失                 | 重试 3 次，失败后可手动从 Redis 恢复 |
| 超时（AI思考久） | 无超时控制，可能无限等待              | 120 秒超时，已接收内容可恢复        |

有人建议我断点续传，但是我认为你的观点可能有混淆，我做出以下解释:

| 传统"断点续传"           | 我的实现                 | 		为什么我的更好          |
|:-------------------|:---------------------|:-------------------|
| 文件传输中断 → 从中断位置继续传输 | 流式传输中断 → 展示已生成的部分回复	 | LLM 无法"续传"，只能"缓存恢复 |
| 文件内容固定，可预测位置       | LLM 生成内容随机，无法预测	     | 你的方案符合 LLM 的特性     |
| 适用于大文件下载           | 适用于对话系统	             | 	你的方案面向实际场景        |

# v -3.6

这个小部分，我实现了那个对话分享的功能，可以实现最基础的那个**对话分享功能**，这样子，用户可以实现将那个对话分享给别人了